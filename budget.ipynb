{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFkjbyCC4QPnJlkYevUkbA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axjasf/YNAB-Categorizer/blob/main/budget.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About\n",
        "\n",
        "* This project is meant to bring all my personal finance related transactions into one easy to understand view.\n",
        "* Scope / Value descriptoon\n",
        "    * ...\n",
        "* Mechanism\n",
        "    * It reads CSV files from several US and German banks and Credit Card processors and harmonizes them into one dataframe.\n",
        "    * It maps fields such as descriptions into payees\n",
        "        * Lookup mechanism (direct hit and prefix hit) against a payee config JSON file\n",
        "        * Matching against similarity vectors per payee to identify candidates (manual adjustment of payee JSON afterwards)\n",
        "    * It categorizes each transaction or splits it into several categories\n",
        "        * by payee\n",
        "        * by pre-determination of a percentage split (e.g. for Walgreens that should be sufficient, given that I have categorized transactions since 2014)\n",
        "        * by semi-automatic order-item review split (e.g. for Apple or Amazon transactions where these files exist and where a split between utility and subscription or grocery, household products or general shopping is of interest)\n",
        "    * It works with a set of indicator field to mark aspects of interest\n",
        "        * Indicator for transactions in which automatic determinations have been taken place\n",
        "        * Task field to address open tasks\n",
        "        * ..."
      ],
      "metadata": {
        "id": "jp_J4Oz5euR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "jDWIT_CWmLBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading of Libraries\n",
        "* Loading of neccessary libraries such as Pandas etc."
      ],
      "metadata": {
        "id": "YFUcNTnFoxgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "754FWtrPPMRN"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define global Variables\n",
        "* Create transactions structure that ultimately will hold the transactions dataframes from all bank files\n",
        "* Create overall transactions dataframe"
      ],
      "metadata": {
        "id": "MQ1-J3IcotCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transactions dataframe and load the JSON configuration for the different banks\n",
        "bank_transactions = {}\n",
        "\n",
        "bank_files = {\n",
        "        \"Chase\": \"chase.csv\",\n",
        "        \"Wells Fargo Checking\": \"wellsfargo_checking.csv\",\n",
        "        \"Apple\": \"apple.csv\",\n",
        "        \"Commerzbank\": \"commerzbank.csv\"\n",
        "    }\n",
        "\n",
        "all_transactions = []"
      ],
      "metadata": {
        "id": "8W7j8YnVNfEX"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File Conversion"
      ],
      "metadata": {
        "id": "DonELYoNmHRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* For each bank file:\n",
        "    * Load file into individual df\n",
        "    * Basic quality control on the individual df level\n",
        "    * Transform columns into target columns\n",
        "        * Add Bank ID field as well as numberical ID field\n",
        "    * Add individual df to transactions df\n",
        "\n",
        "* Special transformations for non-US banks:\n",
        "    * Date conversion\n",
        "    * EUR to USD conversion based on an existing file (date and exchange rate or an API call to a free service)"
      ],
      "metadata": {
        "id": "sV_EgVu5pG3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quality_control(df):\n",
        "    missing_values = df.isnull().sum()\n",
        "    column_data_types = df.dtypes\n",
        "\n",
        "    return missing_values, column_data_types"
      ],
      "metadata": {
        "id": "we4_xBVmKZPX"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_field_names(df, bank=\"\"):\n",
        "\n",
        "    if 'Category' in df.columns:\n",
        "        df = df.rename(columns={\"Category\" : \"oldCategory\"})\n",
        "\n",
        "    df.insert(4, 'SplitID',\"\")\n",
        "    df.insert(0, 'Date','')\n",
        "    df.insert(1, 'Payee','')\n",
        "    df.insert(2, 'Category Type','')\n",
        "    df.insert(3, 'Category','')\n",
        "    df.insert(4, 'chkPayee','')\n",
        "    df.insert(5, 'chkCategory','')\n",
        "    df.insert(6, 'chkSplit','')\n",
        "    df.insert(7, 'chkEURUSD','')\n",
        "\n",
        "#    if bank == \"Commerzbank\":\n",
        "#        df.insert(\"Amount (USD)\")\n",
        "#        df = df.rename(columns={\"Booking text\" : \"Description\"})\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "sx688qkjJyLA"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wells Fargo"
      ],
      "metadata": {
        "id": "iSkK3j8oYDrW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wells Fargo Checking"
      ],
      "metadata": {
        "id": "OKPVENVyYGzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Wells Fargo Checking CSV\n",
        "bank = 'Wells Fargo Checking'\n",
        "bank_transactions[bank] = pd.read_csv(bank_files[bank], header=None, names=[\"Transaction Date\", \"Amount (USD)\", \"Status\", \"Memo\", \"Description\"])\n",
        "\n",
        "# Adjust field names (if any specific adjustments are required)\n",
        "\n",
        "# Convert 'Transaction Date' column to datetime\n",
        "bank_transactions[bank]['Date'] = pd.to_datetime(bank_transactions[bank]['Transaction Date'], errors='coerce')\n",
        "\n",
        "# Check for problematic dates (rows where the date conversion failed)\n",
        "problematic_dates = bank_transactions[bank][bank_transactions[bank]['Date'].isna()]\n",
        "\n",
        "# Perform quality control checks\n",
        "missing_values, column_data_types = quality_control(bank_transactions[bank])\n",
        "\n",
        "# Drop columns that are not needed\n",
        "bank_transactions[bank] = bank_transactions[bank].drop(columns=['Transaction Date', 'Status', 'Memo'])  # Assuming 'Status' is not needed, adjust as necessary\n",
        "\n",
        "bank_transactions[bank]"
      ],
      "metadata": {
        "id": "3ayfeFcIJeLo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "7914a25c-eb95-415f-9202-b380478f5856"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Amount (USD)                                        Description  \\\n",
              "0           95.05  PAYPAL TRANSFER 230902 1029162881620 AXEL JANSSEN   \n",
              "1           95.04  PAYPAL TRANSFER 230902 1029162851130 AXEL JANSSEN   \n",
              "2           29.11  PAYPAL TRANSFER 230902 1029162775449 AXEL JANSSEN   \n",
              "3        -1200.00                                       CHECK # 1177   \n",
              "4         -775.00  RECURRING TRANSFER TO JANSSEN A SAVINGS REF #O...   \n",
              "..            ...                                                ...   \n",
              "223       -107.50  VANGUARD BUY INVESTMENT 123022 163602703163938...   \n",
              "224       -105.00  VANGUARD BUY INVESTMENT 123022 696785703164948...   \n",
              "225        426.46          MOBILE DEPOSIT : REF NUMBER :915030444929   \n",
              "226        207.63          MOBILE DEPOSIT : REF NUMBER :815030443890   \n",
              "227       1021.46          MOBILE DEPOSIT : REF NUMBER :415030440299   \n",
              "\n",
              "          Date  \n",
              "0   2023-09-05  \n",
              "1   2023-09-05  \n",
              "2   2023-09-05  \n",
              "3   2023-09-01  \n",
              "4   2023-09-01  \n",
              "..         ...  \n",
              "223 2023-01-03  \n",
              "224 2023-01-03  \n",
              "225 2023-01-03  \n",
              "226 2023-01-03  \n",
              "227 2023-01-03  \n",
              "\n",
              "[228 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d90394dd-8ebd-4d4d-9d9a-9247e1cf11f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Amount (USD)</th>\n",
              "      <th>Description</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95.05</td>\n",
              "      <td>PAYPAL TRANSFER 230902 1029162881620 AXEL JANSSEN</td>\n",
              "      <td>2023-09-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>95.04</td>\n",
              "      <td>PAYPAL TRANSFER 230902 1029162851130 AXEL JANSSEN</td>\n",
              "      <td>2023-09-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29.11</td>\n",
              "      <td>PAYPAL TRANSFER 230902 1029162775449 AXEL JANSSEN</td>\n",
              "      <td>2023-09-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1200.00</td>\n",
              "      <td>CHECK # 1177</td>\n",
              "      <td>2023-09-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-775.00</td>\n",
              "      <td>RECURRING TRANSFER TO JANSSEN A SAVINGS REF #O...</td>\n",
              "      <td>2023-09-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>-107.50</td>\n",
              "      <td>VANGUARD BUY INVESTMENT 123022 163602703163938...</td>\n",
              "      <td>2023-01-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>-105.00</td>\n",
              "      <td>VANGUARD BUY INVESTMENT 123022 696785703164948...</td>\n",
              "      <td>2023-01-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>426.46</td>\n",
              "      <td>MOBILE DEPOSIT : REF NUMBER :915030444929</td>\n",
              "      <td>2023-01-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>207.63</td>\n",
              "      <td>MOBILE DEPOSIT : REF NUMBER :815030443890</td>\n",
              "      <td>2023-01-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>1021.46</td>\n",
              "      <td>MOBILE DEPOSIT : REF NUMBER :415030440299</td>\n",
              "      <td>2023-01-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>228 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d90394dd-8ebd-4d4d-9d9a-9247e1cf11f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d90394dd-8ebd-4d4d-9d9a-9247e1cf11f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d90394dd-8ebd-4d4d-9d9a-9247e1cf11f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6c03ac88-ea22-4862-ba44-41119018ea82\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c03ac88-ea22-4862-ba44-41119018ea82')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6c03ac88-ea22-4862-ba44-41119018ea82 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chase"
      ],
      "metadata": {
        "id": "uGfOhoFalRcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bank = 'Chase'\n",
        "bank_transactions[bank] = pd.read_csv(bank_files[bank])\n",
        "\n",
        "bank_transactions[bank] = adjust_field_names(bank_transactions[bank])\n",
        "\n",
        "bank_transactions[bank]['Date'] = pd.to_datetime(bank_transactions[bank]['Transaction Date'], errors='coerce')\n",
        "problematic_dates = bank_transactions[bank][bank_transactions[bank]['Date'].isna()]\n",
        "missing_values, column_data_types = quality_control(bank_transactions[bank])\n",
        "\n",
        "bank_transactions[bank] = bank_transactions[bank].drop(columns=['Post Date', 'oldCategory', 'Type', 'Memo', 'Transaction Date'])\n",
        "bank_transactions[bank] = bank_transactions[bank].rename(columns={\"Amount\" : \"Amount (USD)\"})\n"
      ],
      "metadata": {
        "id": "S2SUWsyGYA0d"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apple"
      ],
      "metadata": {
        "id": "_PiuqQMNlTrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bank = 'Apple'\n",
        "bank_transactions[bank] = pd.read_csv(bank_files[bank])\n",
        "\n",
        "bank_transactions[bank] = adjust_field_names(bank_transactions[bank], bank)\n",
        "\n",
        "bank_transactions[bank]['Date'] = pd.to_datetime(bank_transactions[bank]['Transaction Date'], errors='coerce')\n",
        "problematic_dates = bank_transactions[bank][bank_transactions[bank]['Date'].isna()]\n",
        "missing_values, column_data_types = quality_control(bank_transactions[bank])\n",
        "\n",
        "bank_transactions[bank] = bank_transactions[bank].drop(columns=['Transaction Date', 'Clearing Date', 'Merchant', 'oldCategory', 'Type', 'Purchased By'])"
      ],
      "metadata": {
        "id": "Fb8FLo8XeVqt"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Commerzbank"
      ],
      "metadata": {
        "id": "N8bnZFhBlU8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bank = 'Commerzbank'\n",
        "bank_transactions[bank] = pd.read_csv(bank_files[bank])\n",
        "\n",
        "bank_transactions[bank] = adjust_field_names(bank_transactions[bank])\n",
        "\n",
        "\n",
        "bank_transactions[bank]['Date'] = pd.to_datetime(bank_transactions[bank]['Transaction date'], errors='coerce', format='%d.%m.%Y') # For Commerzbank, Day.Month.Year\n",
        "problematic_dates = bank_transactions[bank][bank_transactions[bank]['Date'].isna()]\n",
        "missing_values, column_data_types = quality_control(bank_transactions[bank])\n",
        "\n",
        "bank_transactions[bank] = bank_transactions[bank][bank_transactions[bank]['Amount'] != 0]\n",
        "\n",
        "\n",
        "bank_transactions[bank].insert(7, \"Amount (USD)\",\"\")\n",
        "\n",
        "bank_transactions[bank] = bank_transactions[bank].rename(columns={\"Booking text\" : \"Description\"})\n",
        "\n",
        "### EUR to USD conversion\n",
        "# https://www.wsj.com/market-data/quotes/fx/EURUSD/historical-prices\n",
        "\n",
        "exchange_rates_data = pd.read_csv('eur_usd_exchange_rates.csv')\n",
        "\n",
        "# Convert the date columns to consistent datetime format\n",
        "exchange_rates_data['Date'] = pd.to_datetime(exchange_rates_data['Date'], format='%m/%d/%Y')\n",
        "\n",
        "# Merge on the date columns to add the exchange rate to bank_transactions[bank]\n",
        "bank_transactions[bank] = bank_transactions[bank].merge(exchange_rates_data[['Date', ' Close']], on='Date', how='left')\n",
        "\n",
        "# Add the chkEURUSD column based on the ' Close' column value\n",
        "bank_transactions[bank]['chkEURUSD'] = np.where(bank_transactions[bank][' Close'].isna(), 'E', 'A')\n",
        "\n",
        "# Convert the Amount from EUR to USD\n",
        "bank_transactions[bank]['Amount (USD)'] = bank_transactions[bank]['Amount'] * bank_transactions[bank][' Close']\n",
        "\n",
        "# Drop the ' Close' column as it's not needed anymore in bank_transactions[bank]\n",
        "bank_transactions[bank].drop(' Close', axis=1, inplace=True)\n",
        "\n",
        "### End of currency conversion\n",
        "\n",
        "#bank_transactions[bank].drop(bank_transactions[bank].columns[[16, 15, 14, 13, 12, 10, 9, 8]], axis=1, inplace=True)\n",
        "bank_transactions[bank] = bank_transactions[bank].drop(columns=['Transaction date', 'Value date', 'Transaction type', 'Amount', 'Account of initiator', 'Bank code of account of initiator', 'IBAN of account of initiator'])\n"
      ],
      "metadata": {
        "id": "qLtMUpw7e1Wx"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_transactions = pd.concat(bank_transactions, keys=bank_transactions.keys())\n",
        "all_transactions['Account-ID'] = all_transactions.index.get_level_values(0) + \"-\" + all_transactions.index.get_level_values(1).astype(str)"
      ],
      "metadata": {
        "id": "W4NvjMwc3FRS"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Payees"
      ],
      "metadata": {
        "id": "qvAQCjR02_0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Payee Harmonization"
      ],
      "metadata": {
        "id": "IQ2XK_tVq09c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "class MerchantMatcher:\n",
        "    def __init__(self, data_df):\n",
        "        self.data = data_df\n",
        "        self.vectorizer = self._train_vectorizer()\n",
        "        self.payee_vectors = self._compute_payee_vectors()\n",
        "        self.positive_list_descriptions = self._get_positive_list_descriptions()\n",
        "\n",
        "    def _match_prefix(self, description, merchant_details):\n",
        "        prefix_length = merchant_details.get('Prefix Length', 50)\n",
        "        for known_description in merchant_details['Positive List']:\n",
        "            truncated_payee = known_description.lower()[:prefix_length]\n",
        "            if description.lower().startswith(truncated_payee):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "\n",
        "    def _train_vectorizer(self):\n",
        "        all_descriptions = [desc.lower() for descriptions in self.data['Positive List'] for desc in descriptions]\n",
        "        return TfidfVectorizer().fit(all_descriptions)\n",
        "\n",
        "    def _compute_payee_vectors(self):\n",
        "        payee_vectors = {}\n",
        "        for merchant, details in self.data.iterrows():\n",
        "            tfidf_matrix = self.vectorizer.transform([desc.lower() for desc in details['Positive List']])\n",
        "            avg_vector = np.asarray(tfidf_matrix.mean(axis=0))\n",
        "            payee_vectors[merchant] = avg_vector\n",
        "        return payee_vectors\n",
        "\n",
        "    def _get_positive_list_descriptions(self):\n",
        "        return set(desc.lower() for descriptions in self.data['Positive List'] for desc in descriptions)\n",
        "\n",
        "    def predict_payees(self, transaction_df):\n",
        "        mg_values = []\n",
        "        chkpayee_values = []\n",
        "        candidates = []\n",
        "\n",
        "        for _, row in transaction_df.iterrows():\n",
        "            description_lower = row['Description'].lower() if row['Description'] else None\n",
        "            current_merchant = None\n",
        "            current_chkpayee = None\n",
        "\n",
        "            if pd.isna(description_lower) or not description_lower.strip():\n",
        "                mg_values.append(None)\n",
        "                chkpayee_values.append(None)\n",
        "                continue\n",
        "\n",
        "            for merchant, details in self.data.iterrows():\n",
        "                if description_lower in [desc.lower() for desc in details['Positive List']]:\n",
        "                    current_merchant = merchant\n",
        "                    current_chkpayee = 'A'\n",
        "                    break\n",
        "\n",
        "                # Check for prefix matching\n",
        "                if self._match_prefix(description_lower, details):\n",
        "                    current_merchant = merchant\n",
        "                    current_chkpayee = 'P'\n",
        "                    break\n",
        "\n",
        "            if not current_merchant:\n",
        "                description_vector = self.vectorizer.transform([description_lower])\n",
        "                similarities = {merchant: linear_kernel(description_vector, np.asarray(vector))[0][0] for merchant, vector in self.payee_vectors.items()}\n",
        "                predicted_merchant = max(similarities, key=similarities.get)\n",
        "                max_similarity = similarities[predicted_merchant]\n",
        "\n",
        "                if max_similarity > self.data.loc[predicted_merchant, 'Threshold']:\n",
        "                    candidates.append({'Payee': predicted_merchant, 'Description': row['Description'], 'Probability': max_similarity})\n",
        "\n",
        "            mg_values.append(current_merchant)\n",
        "            chkpayee_values.append(current_chkpayee or 'C')\n",
        "\n",
        "        transaction_df['Payee'] = mg_values\n",
        "        transaction_df['chkPayee'] = chkpayee_values\n",
        "        candidates_df = pd.DataFrame(candidates)\n",
        "        return transaction_df, candidates_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Sample Usage\n",
        "data_df = pd.read_json(\"payee_matching.json\", orient=\"index\")  # Replace with your DataFrame loading mechanism\n",
        "\n",
        "matcher = MerchantMatcher(data_df)\n",
        "payees_identified_df, payees_candidates_df = matcher.predict_payees(all_transactions)\n",
        "payees_identified_df = payees_identified_df[payees_identified_df['chkPayee'] != 'C']\n",
        "\n",
        "file_payees_identified = \"z_payees_identified.csv\"\n",
        "file_payees_candidates = \"z_payees_candidates.csv\"\n",
        "\n",
        "if os.path.exists(file_payees_identified): os.remove(file_payees_identified)\n",
        "if os.path.exists(file_payees_candidates): os.remove(file_payees_candidates)\n",
        "payees_identified_df.to_csv(file_payees_identified, index=False)\n",
        "payees_candidates_df.to_csv(file_payees_candidates, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "qh_Ltgm3iSlk"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categories"
      ],
      "metadata": {
        "id": "DF0bxKmWmsz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Transactions <--> Payee mapping (1:1)\n",
        "* Transactions <--> Amazon Orders mapping and splitting\n",
        "* Transactions <--> Apple Orders mapping and splitting\n",
        "* Transactions <--> Walgreens splitting"
      ],
      "metadata": {
        "id": "ol1JCGCXmkqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Direct assignment"
      ],
      "metadata": {
        "id": "u4CttrmftPPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transactions <--> Payee mapping (1:1)\n",
        "\n",
        "with open('payee_matching.json', 'r') as file:\n",
        "    payee_data = json.load(file)\n",
        "\n",
        "# List to hold split transactions\n",
        "split_transactions = []\n",
        "\n",
        "# Iterate over each row in the dataframe\n",
        "for idx, row in all_transactions.iterrows():\n",
        "    payee = row['Payee']\n",
        "\n",
        "    # Check if payee exists in the JSON data\n",
        "    if payee in payee_data:\n",
        "        categories = payee_data[payee]['Categories']\n",
        "\n",
        "        # If no category exists, update the row's category columns\n",
        "        if len(categories) == 0:\n",
        "            all_transactions.at[idx, 'chkCategory'] = 'E'\n",
        "\n",
        "        # If only one category exists, update the row's category columns\n",
        "        if len(categories) == 1:\n",
        "            all_transactions.at[idx, 'Category Type'] = categories[0]['Category Type']\n",
        "            all_transactions.at[idx, 'Category'] = categories[0]['Category']\n",
        "            all_transactions.at[idx, 'chkCategory'] = 'A'\n",
        "\n",
        "        # If multiple categories exist, create split transactions\n",
        "        elif len(categories) > 1:\n",
        "            all_transactions.at[idx, 'Category Type'] = ''  # Empty the master row's category columns\n",
        "            all_transactions.at[idx, 'Category'] = ''\n",
        "            all_transactions.at[idx, 'SplitID'] = str(row['Account-ID']) + '-' + 'M'\n",
        "            all_transactions.at[idx, 'chkCategory'] = 'A'\n",
        "\n",
        "            for idx_split, category in enumerate(categories, start=1):\n",
        "                new_row = row.copy()\n",
        "                new_row['Category Type'] = category['Category Type']\n",
        "                new_row['Category'] = category['Category']\n",
        "                new_row['SplitID'] = str(row['Account-ID']) + '-' + 'S' + str(idx_split-1)\n",
        "                new_row['chkCategory'] = 'A'\n",
        "\n",
        "                # Update the 'Amount (USD)' based on the percentage split from the JSON\n",
        "                new_row['Amount (USD)'] = row['Amount (USD)'] * category.get('Percentage', 1)\n",
        "\n",
        "                split_transactions.append(new_row)\n",
        "\n",
        "# Append the split transactions to the main dataframe\n",
        "all_transactions = pd.concat([all_transactions, pd.DataFrame(split_transactions)], ignore_index=False)"
      ],
      "metadata": {
        "id": "s4LpNZWV_dgB"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Amazon categorization\n",
        "\n",
        "1. **Identification of Amazon Transactions**:\n",
        "* Filter transactions with the Payee set to \"Amazon\" or \"Amazon Grocery\".\n",
        "* From this subset, take those transactions that don't already have a chkCategory flag.\n",
        "   \n",
        "2. **Match the Transactions to Orders**:\n",
        "   - For each identified Amazon transaction, we need to match it with an order from the Amazon order file. This matching will be based on the transaction date (with a tolerance of a few days) and the payment amount.\n",
        "   \n",
        "3. **Extract Items for the Matched Orders**:\n",
        "   - Once we have identified the matching order, we will then look up the items related to that order from the Amazon order items file.\n",
        "   \n",
        "4. **Categorize the Items**:\n",
        "   - We will categorize the items into two groups:\n",
        "     - Groceries (Split 1)\n",
        "     - All other line items (Split 2...n)\n",
        "   \n",
        "5. **Modify the Transactions**:\n",
        "   - We will then modify the transactions to reflect these splits, updating the description for each split with the appropriate line item description."
      ],
      "metadata": {
        "id": "tiI3oyFtzzf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "class AmazonProcessor:\n",
        "    def __init__(self, orders_headers, order_items=None, grocery_keywords=None):\n",
        "        self.orders_headers = orders_headers\n",
        "        self.order_items = order_items\n",
        "        self.grocery_keywords = grocery_keywords\n",
        "        self.processed_orders = self.split_multiple_payments(orders_headers)\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_multiple_payments(payment_string):\n",
        "        # Match both types: \"2023-08-04: $14.98\" and \"MasterCard ending in 3490: August 23, 2023: $39.08\"\n",
        "        pattern = r\"(?:MasterCard|Visa)?(?:\\s*ending\\s*in\\s*\\d{4})?:?\\s*([A-Za-z]*\\s*\\d{1,2},?\\s*\\d{4}|\\d{4}-\\d{1,2}-\\d{1,2})[^$]*\\$\\s*([\\d,]+\\.\\d{2})\"\n",
        "        matches = re.findall(pattern, payment_string)\n",
        "\n",
        "        # Convert month names to month numbers for consistent date format\n",
        "        month_names = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
        "        month_map = {month: str(index + 1) for index, month in enumerate(month_names)}\n",
        "\n",
        "        # Process the dates to have a consistent format\n",
        "        processed_matches = []\n",
        "        for date, amount in matches:\n",
        "            for month, month_num in month_map.items():\n",
        "                date = date.replace(month, month_num)\n",
        "            date = date.replace(\",\", \"\").replace(\" \", \"-\")\n",
        "            processed_matches.append((date, float(amount.replace(',', ''))))\n",
        "\n",
        "        return processed_matches\n",
        "\n",
        "    def split_multiple_payments(self, df):\n",
        "        new_rows = []\n",
        "        for _, row in df.iterrows():\n",
        "            payments = self.extract_multiple_payments(row['payments'])\n",
        "            for date, amount in payments:\n",
        "                new_row = row.copy()\n",
        "                new_row['payment_date'] = date\n",
        "                new_row['payment_amount'] = amount\n",
        "                new_rows.append(new_row)\n",
        "        return pd.DataFrame(new_rows)\n",
        "\n",
        "    def get_processed_orders(self):\n",
        "        return self.processed_orders.copy()\n",
        "\n",
        "# Sample Usage in Google Colab:\n",
        "# Assuming you've uploaded 'amazon_axel_orders_headers_jul_aug.csv'\n",
        "orders_headers_df = pd.read_csv(\"/content/amazon_axel_orders_headers_jul_aug.csv\")\n",
        "amazon_processor = AmazonProcessor(orders_headers_df)\n",
        "order_data_processed = amazon_processor.get_processed_orders()\n",
        "\n",
        "order_data_processed\n",
        "\n"
      ],
      "metadata": {
        "id": "G05g5zt07HT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AmazonTransactionMatcher:\n",
        "    def __init__(self, order_data, transaction_data):\n",
        "        self.order_data = order_data\n",
        "        self.transaction_data = transaction_data\n",
        "        self.matches = pd.DataFrame()\n",
        "\n",
        "    def match_transactions(self):\n",
        "        # Convert 'payment_date' in order_data to datetime format\n",
        "        self.order_data['payment_date'] = pd.to_datetime(self.order_data['payment_date'])\n",
        "\n",
        "        # Merge based on payment_date and payment_amount\n",
        "        self.matches = pd.merge(\n",
        "            left=self.transaction_data,\n",
        "            right=self.order_data,\n",
        "            left_on=['Date', 'Amount (USD)'],\n",
        "            right_on=['payment_date', 'payment_amount'],\n",
        "            how='inner'\n",
        "        )\n",
        "\n",
        "    def get_matched_transactions(self):\n",
        "        return self.matches.copy()\n",
        "\n",
        "\n",
        "# Assuming 'all_transactions' is the DataFrame containing your transactions\n",
        "matcher = AmazonTransactionMatcher(processed_orders, all_transactions)\n",
        "matcher.match_transactions()\n",
        "matched_transactions = matcher.get_matched_transactions()\n",
        "print(matched_transactions.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpGyBmcHC38K",
        "outputId": "cac04ac5-63a9-48bd-c1d6-6b995230b972"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Date, Account-ID, SplitID, Payee, Category Type, Category, Amount (USD), Description, chkPayee, chkCategory, chkEURUSD, order id, items, to, date, total, shipping, shipping_refund, gift, tax, refund, payments, payment_date, payment_amount]\n",
            "Index: []\n",
            "\n",
            "[0 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output"
      ],
      "metadata": {
        "id": "auc-YLI0qPmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataframe preparation"
      ],
      "metadata": {
        "id": "Ojxb0cORqS37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reorder Columns\n",
        "\n",
        "all_transactions = all_transactions[[\n",
        "    'Date',\n",
        "    'Account-ID',\n",
        "    'SplitID',\n",
        "    'Payee',\n",
        "    'Category Type',\n",
        "    'Category',\n",
        "    'Amount (USD)',\n",
        "    'Description',\n",
        "    'chkPayee',\n",
        "    'chkCategory',\n",
        "    'chkEURUSD']]\n",
        "\n",
        "# Sort rows\n",
        "all_transactions = all_transactions.sort_values(by=['Date', 'Account-ID', 'SplitID'], ascending=[False, True, True])\n",
        "\n",
        "# Formating\n",
        "all_transactions['Amount (USD)'] = all_transactions['Amount (USD)'].round(2)\n",
        "all_transactions['Amount (USD)'] = all_transactions['Amount (USD)'].apply(lambda x: \"${:,.2f}\".format(x))\n"
      ],
      "metadata": {
        "id": "EJTopk0eo8Ec"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output file generation"
      ],
      "metadata": {
        "id": "tbGNVP1OrelH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(\"z_output.csv\"): os.remove(\"z_output.csv\")\n",
        "all_transactions.to_csv(\"z_output.csv\", index=False)"
      ],
      "metadata": {
        "id": "glF2a7uTBl9T"
      },
      "execution_count": 111,
      "outputs": []
    }
  ]
}